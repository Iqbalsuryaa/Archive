{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# TUGAS 3: UJICOBA COSINUS SIMILARITY PYTHON"],"metadata":{"id":"rk61zSDwrtDr"}},{"cell_type":"markdown","source":["Nama : MOHAMMAD IQBAL SURYA RAMADHAN\n","\n","NIM  : 210411100002\n","\n","KELAS: TKI - B\n","\n","cosim_210411100002_2"],"metadata":{"id":"iw1XfLYi9B26"}},{"cell_type":"markdown","source":["# Cosinus Similatarity dengan python"],"metadata":{"id":"BZ2VCN509FBB"}},{"cell_type":"code","source":["from google.colab import drive \n","drive.mount ('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PrvlNxvv9CaY","outputId":"585f809d-b665-49b0-c9fb-78b7f25d5d39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["pip install Sastrawi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j9sWGpUV9Mr5","outputId":"ea2be5ef-daa4-4c82-bf89-6d58a199065e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting Sastrawi\n","  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Sastrawi\n","Successfully installed Sastrawi-1.0.1\n"]}]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n","import re"],"metadata":{"id":"XRC9zMFc9RK5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["REGEX = re.compile(r\"\\s\")\n","def tokenize(text):\n","    return [tok.strip().lower() for tok in REGEX.split(text)]\n","\n","def stopwords(text):\n","\treg = re.compile(r\"\\n\")\n","\treturn reg.split(text)"],"metadata":{"id":"N3GkC0u_9TBS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file = open(\"drive/MyDrive/Tugas3TKI2/source1.txt\",\"r\");\n","raw1 = file.read()\n","\n","file = open(\"drive/MyDrive/Tugas3TKI2/source2.txt\",\"r\");\n","raw2 = file.read()\n","\n","file = open(\"drive/MyDrive/Tugas3TKI2/source3.txt\",\"r\");\n","raw3 = file.read()\n","\n","file = open(\"drive/MyDrive/Tugas3TKI2/source4.txt\",\"r\");\n","raw4 = file.read()\n","\n","file = open(\"drive/MyDrive/Tugas3TKI2/source5.txt\",\"r\");\n","raw5 = file.read()"],"metadata":{"id":"C1FKe1nK9Ury"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# menghilangkan tanda baca\n","tandabaca = [\".\",\",\",\"-\",\"%\"]\n","for td in tandabaca:\n","\traw1=raw1.replace(td,\"\")\n","\traw2=raw2.replace(td,\"\")\n","\traw3=raw3.replace(td,\"\")\n","\traw4=raw4.replace(td,\"\")\n","\traw5=raw5.replace(td,\"\")"],"metadata":{"id":"7f5YxVbG9e7M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# menghilangkan stop words\n","file = open(\"drive/MyDrive/Tugas3TKI/stopwords.txt\",\"r\");\n","st = file.read()\n","stopwords = stopwords(st)\n","\n","for word in stopwords:\n","\traw1=raw1.replace(\" \"+word+\" \",\" \")\n","\traw2=raw2.replace(\" \"+word+\" \",\" \")\n","\traw3=raw3.replace(\" \"+word+\" \",\" \")\n","\traw4=raw4.replace(\" \"+word+\" \",\" \")\n","\traw5=raw5.replace(\" \"+word+\" \",\" \")"],"metadata":{"id":"Eo1jAEnn9gp0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# stemming \n","factory = StemmerFactory()\n","stemmer = factory.create_stemmer()\n","\n","\n","hasilstem1 = stemmer.stem(raw1)\n","hasilstem2 = stemmer.stem(raw2)\n","hasilstem3 = stemmer.stem(raw3)\n","hasilstem4 = stemmer.stem(raw4)\n","hasilstem5 = stemmer.stem(raw5)"],"metadata":{"id":"xHnayq9G9joF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#tokenization\n","train_set = [hasilstem1,hasilstem2,hasilstem3,hasilstem4,hasilstem5]"],"metadata":{"id":"iOlC7qQ39lUd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["count_vectorizer = CountVectorizer(tokenizer=tokenize)\n","data = count_vectorizer.fit_transform(train_set).toarray()\n","vocab = count_vectorizer.get_feature_names_out()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1ruKtTE9nAQ","outputId":"d504d7f2-eb80-4a7e-f41e-f40a65a26363"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["print (\"Jumlah Term FREQUENCY=============================\")\n","print (data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bbi0u8ax9nkc","outputId":"591603c4-1b2d-4f0b-9509-7670a90ee449"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Jumlah Term FREQUENCY=============================\n","[[0 1 0 ... 3 0 0]\n"," [0 1 0 ... 0 0 0]\n"," [0 0 0 ... 1 0 4]\n"," [0 1 1 ... 0 0 0]\n"," [1 1 0 ... 0 1 0]]\n"]}]},{"cell_type":"code","source":["print (\"VECTOR FITUR=============================\")\n","print (vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NUVNmODy9r13","outputId":"fec19b25-0415-4426-8a53-3867bf5bcb7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VECTOR FITUR=============================\n","['2022' '2023' '21' '23' '230323' '25' '3' '7' '99' 'acara' 'acu' 'ada'\n"," 'adapun' 'agustus' 'aisha' 'ajar' 'akselerasi' 'akun' 'alam' 'alami'\n"," 'aldiano' 'alfian' 'alih' 'and' 'andi' 'angkasa' 'anjing' 'anjur' 'antar'\n"," 'anti' 'antibodi' 'apa' 'api' 'ardianto' 'asn' 'awat' 'bagi' 'bagus'\n"," 'bahagia' 'baik' 'bakar' 'bal' 'banding' 'bantu' 'barang' 'bas' 'batas'\n"," 'baterai' 'bayar' 'bbm' 'beber' 'beda' 'beli' 'belum' 'benarbenar'\n"," 'beramahtamah' 'berapa' 'berita' 'bernardi' 'bersamasama' 'biaya'\n"," 'bilang' 'bising' 'boleh' 'bolehboleh' 'buah' 'buahbuahan' 'buang' 'buka'\n"," 'bukber' 'busana' 'cabut' 'cegah' 'cepat' 'combustion' 'contoh' 'corona'\n"," 'covid19' 'cuit' 'curi' 'daerah' 'dalam' 'dan' 'dara' 'data' 'dengan'\n"," 'denpasar' 'deret' 'detikcom' 'di' 'dia' 'direktur' 'ditreskrimum'\n"," 'djumiril' 'doctor' 'dokter' 'dorong' 'dr' 'dua' 'efisien' 'ekor'\n"," 'embelembel' 'emisi' 'empat' 'end' 'energi' 'engine' 'entertaimet'\n"," 'fajar' 'fakultas' 'februari' 'fkm' 'foto' 'gagah' 'ganti' 'gas' 'gaun'\n"," 'gejala' 'gemerlap' 'gencar' 'gesits' 'giat' 'guna' 'hadap' 'hadir' 'hal'\n"," 'harap' 'harga' 'hari' 'haruni' 'harus' 'hasil' 'hemat' 'hewan' 'hias'\n"," 'hidup' 'hilang' 'hitam' 'ia' 'ice' 'ikan' 'imunitas' 'indonesia'\n"," 'industri' 'ini' 'instagram' 'internal' 'investigasi' 'istri' 'izin'\n"," 'jabat' 'jadi' 'jaga' 'jahat' 'jakarta' 'jalin' 'jangkit' 'janji' 'jas'\n"," 'jaya' 'joko' 'junior' 'juta' 'kalau' 'kamis' 'kasubdit' 'kasus' 'kau'\n"," 'kblbb' 'keluar' 'keluarga' 'kemarin' 'kembang' 'kemeja' 'kemenkes'\n"," 'kena' 'kendara' 'kerabat' 'ketat' 'kevin' 'khawatir' 'khomeini' 'kita'\n"," 'kocek' 'koko' 'koko28' 'kolom' 'kompol' 'komponen' 'kondisi'\n"," 'konferensi' 'konvensional' 'korban' 'kualitas' 'kumpulkumpul' 'kutip'\n"," 'lain' 'laku' 'lalu' 'lamar' 'langit' 'langsung' 'lantar' 'lapor'\n"," 'larang' 'latar' 'lebih' 'legalitas' 'lengkap' 'lingkung' 'listrik'\n"," 'lokal' 'lutut' 'mahal' 'makan' 'malam' 'mana' 'manfaat' 'manufaktur'\n"," 'marak' 'maret' 'masa' 'masih' 'masingmasing' 'masker' 'masyarakat' 'me'\n"," 'media' 'meni' 'menteri' 'menu' 'merek' 'mereka' 'mesin' 'meski' 'metro'\n"," 'milik' 'momen' 'momentum' 'motor' 'mudah' 'muhammad' 'murah' 'musibah'\n"," 'namun' 'nasi' 'network' 'ngasih' 'nggak' 'nikah' 'nila' 'of'\n"," 'operasional' 'orang' 'orangorang' 'otomotif' 'outdoor' 'pacar' 'pakai'\n"," 'pamer' 'pandemi' 'paris' 'pasal' 'pasang' 'pebulutangkis' 'pelihara'\n"," 'pengantin' 'perintah' 'pers' 'persen' 'peser' 'pilih' 'pola' 'polda'\n"," 'polisi' 'ppkm' 'prancis' 'presiden' 'proses' 'protokol' 'puasa'\n"," 'pungkas' 'putih' 'rabies' 'rakyat' 'ramah' 'rangkul' 'ranmor' 'rekan'\n"," 'rendah' 'resmi' 'responsif' 'ri' 'rian' 'riset' 'roda' 'rogoh' 'rp'\n"," 'rumit' 'saat' 'sabtu' 'sakit' 'saksi' 'salah' 'sambung' 'samping' 'sang'\n"," 'sangkut' 'sanjaya' 'sapa' 'saran' 'satu' 'sayur' 'sebut' 'sehat'\n"," 'selebritas' 'semat' 'sementara' 'sempat' 'senang' 'seperti' 'serasi'\n"," 'serosurvei' 'setel' 'sheila' 'siapa' 'silaturahmi' 'situ' 'sosial'\n"," 'spesialis' 'stadion' 'story' 'suami' 'suara' 'subsidi' 'suci' 'sudah'\n"," 'suntik' 'sweet' 'tak' 'takdir' 'tampil' 'tamu' 'tanoesoedibjo' 'tapi'\n"," 'tatap' 'tekuk' 'telur' 'temu' 'terang' 'terap' 'tetap' 'the' 'tidak'\n"," 'tiga' 'time' 'tindaklanjuti' 'tkp' 'torsi' 'tubuh' 'tuju' 'tukas'\n"," 'tuksedo' 'tulis' 'tumbuh' 'turut' 'ucap' 'ui' 'unggah' 'unggul' 'unit'\n"," 'universitas' 'until' 'untung' 'upaya' 'utama' 'vaksin' 'vaksinasi'\n"," 'valencia' 'via' 'vidi' 'virus' 'walaupun' 'warga' 'warna' 'widodo'\n"," 'wika' 'ya' 'you' 'yuliansyah']\n"]}]},{"cell_type":"code","source":["print (\"JUMLAH VECTOR FITUR=============================\")\n","print (len(vocab))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eSb5gSlO9wGu","outputId":"185185ef-2aca-43b7-c578-3045362863e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["JUMLAH VECTOR FITUR=============================\n","390\n"]}]},{"cell_type":"code","source":["tfidf = TfidfVectorizer().fit_transform(train_set)\n","pairwise_similarity = tfidf * tfidf.T"],"metadata":{"id":"Cet8X4uF9w5O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print (\"Jumlah Term FREQUENCY-Inverse Document Frequency=============================\")\n","print (tfidf)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VcFmSjan9ysP","outputId":"c5535201-19b9-4213-f04f-5777f0659dc7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Jumlah Term FREQUENCY-Inverse Document Frequency=============================\n","  (0, 279)\t0.04491504769540274\n","  (0, 325)\t0.04491504769540274\n","  (0, 133)\t0.030080130906393384\n","  (0, 270)\t0.04491504769540274\n","  (0, 13)\t0.04491504769540274\n","  (0, 324)\t0.04491504769540274\n","  (0, 153)\t0.04491504769540274\n","  (0, 316)\t0.13474514308620822\n","  (0, 142)\t0.04491504769540274\n","  (0, 169)\t0.04491504769540274\n","  (0, 176)\t0.04491504769540274\n","  (0, 342)\t0.03623717767251356\n","  (0, 230)\t0.03623717767251356\n","  (0, 213)\t0.03623717767251356\n","  (0, 3)\t0.03623717767251356\n","  (0, 162)\t0.04491504769540274\n","  (0, 161)\t0.07247435534502712\n","  (0, 254)\t0.04491504769540274\n","  (0, 80)\t0.08983009539080548\n","  (0, 35)\t0.08983009539080548\n","  (0, 25)\t0.04491504769540274\n","  (0, 349)\t0.04491504769540274\n","  (0, 115)\t0.13474514308620822\n","  (0, 17)\t0.04491504769540274\n","  (0, 252)\t0.04491504769540274\n","  :\t:\n","  (4, 88)\t0.03787417908631801\n","  (4, 143)\t0.03787417908631801\n","  (4, 366)\t0.07574835817263602\n","  (4, 276)\t0.03787417908631801\n","  (4, 309)\t0.03143898995623984\n","  (4, 301)\t0.03143898995623984\n","  (4, 9)\t0.03787417908631801\n","  (4, 199)\t0.03787417908631801\n","  (4, 133)\t0.06287797991247968\n","  (4, 230)\t0.03787417908631801\n","  (4, 213)\t0.03787417908631801\n","  (4, 3)\t0.03787417908631801\n","  (4, 122)\t0.07574835817263602\n","  (4, 173)\t0.0943169698687195\n","  (4, 87)\t0.07574835817263602\n","  (4, 1)\t0.026447469478004512\n","  (4, 136)\t0.03787417908631801\n","  (4, 212)\t0.03787417908631801\n","  (4, 235)\t0.11362253725895403\n","  (4, 140)\t0.07574835817263602\n","  (4, 311)\t0.03787417908631801\n","  (4, 223)\t0.03143898995623984\n","  (4, 49)\t0.03787417908631801\n","  (4, 152)\t0.026447469478004512\n","  (4, 55)\t0.022369100289197856\n"]}]},{"cell_type":"code","source":["print (\"Jumlah COSINE-SIMILARITY=============================\")\n","print (pairwise_similarity)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U2AZJ-hA92Uf","outputId":"0549e14a-e281-4648-ae8e-545da58c78f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Jumlah COSINE-SIMILARITY=============================\n","  (0, 1)\t0.049606635674658874\n","  (0, 2)\t0.032518514114530064\n","  (0, 4)\t0.056230467372605855\n","  (0, 3)\t0.029625807695633583\n","  (0, 0)\t0.9999999999999989\n","  (1, 2)\t0.0016383370139384085\n","  (1, 4)\t0.0031343163289590356\n","  (1, 3)\t0.002954003239845324\n","  (1, 0)\t0.049606635674658874\n","  (1, 1)\t0.9999999999999999\n","  (2, 1)\t0.0016383370139384085\n","  (2, 0)\t0.032518514114530064\n","  (2, 4)\t0.02591909205718982\n","  (2, 3)\t0.17858610180745066\n","  (2, 2)\t0.9999999999999997\n","  (3, 1)\t0.002954003239845324\n","  (3, 0)\t0.029625807695633583\n","  (3, 2)\t0.17858610180745066\n","  (3, 4)\t0.011673977599406173\n","  (3, 3)\t0.9999999999999996\n","  (4, 1)\t0.0031343163289590356\n","  (4, 0)\t0.056230467372605855\n","  (4, 2)\t0.02591909205718982\n","  (4, 3)\t0.011673977599406173\n","  (4, 4)\t0.9999999999999996\n"]}]},{"cell_type":"markdown","source":["**kesimpulan** **:** \n","\n","Cosine similarity adalah metode yang digunakan untuk mengukur seberapa mirip dua vektor atau dokumen dalam ruang vektor.\n","menggunakan numpy dan scikit-learn untuk menghitung cosine similarity antara dua vektor dan antara beberapa dokumen. Kita menggunakan CountVectorizer dari scikit-learn untuk mengubah dokumen menjadi representasi vektor dan kemudian menghitung cosine similarity antara setiap pasangan dokumen menggunakan cosine_similarity dari scikit-learn.\n","\n","Cosine similarity biasanya digunakan dalam NLP untuk mengukur kesamaan antara dokumen, kata, atau frasa dalam ruang vektor. Semakin tinggi nilai cosine similarity, semakin mirip dokumen atau kata-kata tersebut.\n","\n","Melakukan uji coba cosinus similarity menggunakan Python, untuk menguji kemampuan dan keakuratan perhitungan cosinus similarity dalam membandingkan kedekatan antara dua atau lebih dokumen. Dengan melakukan uji coba, mahasiswa dapat memahami konsep dan cara kerja perhitungan cosinus similarity secara praktis, serta mengevaluasi performa dan akurasi dari implementasi yang dilakukan. dan memperkenalkan berbagai library pendukung yang dapat digunakan untuk mengimplementasikan metode temu kembali informasi, seperti Pandas, Scikit-learn, dan NLTK.\n","\n"],"metadata":{"id":"Z790xbtTDaag"}}]}